#


5. TCP可靠的实现，流量控制，滑动窗口
https://www.cnblogs.com/kubidemanong/p/9987810.html
1）如果发送者不受控制一直发包 接收者的缓存区满了 就会丢包 
2）流量控制 滑动窗口来解决这个问题，滑动窗口是指接收方告知发送方我的接收窗口多大，你不要发多了。
3）那么就出现一个问题，窗口为0的时候，且接收方的窗口不为0的包丢了，这个时候发送方和接收方都在互相等待，进入死锁
4）解决死锁方法就是发送方接收到窗口为0的时候要定时去查窗口大小。


6. 拥塞控制
拥塞就是tcp包在网络中传输在传输过程遇到了拥堵的处理方法。tcp会把丢包就认为是拥堵了。tcp慢开始 假设slow start threshold是16 那么congessionwindow从1 开始然后 2 4 8 12 13 16 17 18....24 拥塞了 就吧slow start threshold 设置为一半就是12  然后cwnd 从1开始 2 4..。
1）慢开始：就是指cwnd从1开始慢慢递增
2）拥塞避免算法：拥塞避免算法是只到了ssthreshold的时候增长变慢 增长是按照1的间隔增加
3）快重传：指丢包后，收到失序的包 三个 就立刻重发 不用等定时重传。
4）快恢复：收到三个重复确认时 不执行慢开始 而是sshreshold减半之后 就执行拥塞算法。



httpdns的ip是anycast

为什么需要心跳

nagle算法和delay ack算法会撞车
tcp慢启动

https慢可能在这里
证书链如何去认证？？？跳DNS？？？
AES证书？？？ECC证书

IP直连，测速， 赛马，那个链接成功快选哪个、 微信方案（实现复杂）

http2 
数据分针，头和body分离

长连接
1、心跳的作用
避免NAT超时
一般60s前台，后台3min

2、错误重传
指数退避
维纳斯 腾讯长连接

3、长连接架构
1、超时做定时器
2、前置服务器？业务服务器？


证书链保证公钥的有效性
密钥协商过程中如何防止中间人攻击

重传次数控制，避免后台雪崩

HTTP

1、http和https的区别
https是http+ssl，HTTP+加密+认证+完整性保护 = HTTPS。

2、HTTP一定是CS架构的，不保存状态，Cookie来管理状态

3、HTTPS为什么不直接用不对称加密，而是用对称加密是因为效率问题
公钥加密组件计算效率往往远低于对称加密组件，直接使用公钥加密组件加密业务数据，这样的性能损耗任何Server都是无法承受的
SSL握手过程就是协商对称加密秘钥的过程

4、HTTP2
HTTP 1.x在应用层以纯文本的形式进行通信，而HTTP 2.0将所有的传输信息分割为更小的消息和帧，并对它们采用二进制格式编码。有了打解包
1）二进制编码压缩
2）复用TCP链接
3）请求一个网页，返回网页并把资源服务器也推送下去


HTTPS
单纯的非对称加密只能保证单向的安全，即client to server的安全，并不能保证server to client的安全
如何协商密钥？？？

客户端传输预埋了公钥所以不需要其他两个随机数

https没有预埋，拿到证书的过程会产生两个随机数

premaster保证密钥的随机性，不被破解

TLS1.2是 2RTT的
1RTT复用Session


TLS1.3的优化
1-RTT ECDH handshake



证书链是什么？？？？

消息认证码
可以理解为加密的哈希


OKHttp的优化
链接复用
ip的选择策略，会ban掉一些失败的ip做排序

Session恢复是什么？？？

Socket
非阻塞IO和IO复用的区别是
非阻塞IO只是查自己的，IO复用的select可以查大家的fd


服务器的Reactor模式
基于事件驱动的IO复用编程


和Proactor模式


后台的阻塞操作很多时候都是依托于IO复用
而客户端直接新建线程阻塞就好了


select、poll、epoll都是IO复用的方法，epoll会改善了点，不了解那么深入了

select是阻塞的，所以不存在空转的情况

加密
DH加密
client用Server的公钥生成私钥和公钥，然后使用对方的公钥和己方的私钥生成加密密钥，使用AES对称加密信息，并把公钥带给Server，Server就可以得到加密的密钥进行解密了
1、过程没有传递对称加密的密钥
2、客户端的私钥都是每次动态生成的

通过数学的方法避免直接传递密钥或者加密后的密钥，更加安全


8、UDP是有边界？
所以sendto(1000),接收端recvfrom(1000)可能会收到900。这个是错误的。所谓数据包，就是说UDP是有界的，sendto(300),sendto(500)；接收到，recvfrom(1000),recvfrom(1000)那么可能会收到300，500或者其中一个或者都没收到。UDP应用层发送的数据，在接收缓存足够的情况下，要么收到全的，要么收不到。
9、粘包
TCP是面向数据流的，所以会有粘包问题，解决粘包就是应用层再设置一个包头设置好包的边界
10、LWIP
又要实时性又要可靠性，还考虑弱网络下
个人觉得主要是两点原因：
tcp的拥塞控制算法，在丢包情况下，会假设网络拥堵，减少发包量。而移动网络环境，弱网络情况丢包的几率较大，会影响游戏的表现，尤其是一些对实时性要求较高的游戏。
tcp面向连接，每个客户端与服务器之间都要建立连接。而在移动网络环境，3g/4g与wifi环境之间切换，断线重连，也会影响游戏表现。
帧同步采取，udp加冗余的方案，一个包丢了还能靠前面或后面的包补充，不触发重传策略，
否则一次重传将带来至少1.5RTT的延迟
王者荣耀 冗余三帧+丢包重传
无线丢包很多时候不是拥塞导致的，是wifi信号差
主要集中在无线丢包触发拥塞控制，导致吞吐下降，我们这里反倒不涉及。我们关心的主要是延时
无限丢包只会导致吞吐下降，吞吐下降了，包堆积也会引起延迟
都是牺牲带宽换延迟，CDN用钱来堆
lwip
不做拥塞控制
减少RTO超时重传时间，但是会带来带宽的浪费
超时重传时间的选择是整个
个人觉得里面比较重要的几个配置项：
重传包发送间隔时间
服务器的KeepAlive包发送间隔
超时重传的时间长度（为RTT的多少倍）
限制的最小RTO为多少毫秒
http://km.oa.com/group/608/articles/show/149287
http://km.oa.com/articles/show/261494?kmref=search&from_page=1&no=1#_Toc425343415
Jitter buffer算法抗抖动
10、研究下MARS？？？
微信对实时性的要求可能不会太高，但是要保证弱网络能发出去东东
MARS的STN了解下
在 Android 系统中，直到16分钟，TCP 才确认失败；在 iOS 系统中，直到1分半到3分半之间，TCP 才确认失败。
在用户体验的接受范围内，尽可能地提高成功率；
保障弱网络下的可用性；
具有网络敏感性，快速地发现新的链路。
使得超时时间过长，在网络波动或拥塞时，无法敏感地发现问题并重试。
1、应用层超时时长的确认，如何敏感地发现链路异常
2、IP切换策略
11、无线网络的丢包率高，成为网络同步方案的一个主要挑战。
http://km.oa.com/articles/show/261494?kmref=search&from_page=1&no=1#_Toc425343415
12、带宽、可靠性、实时性之间的矛盾
高带宽流量可以提高可靠性和实时性也会降低可靠性和实时性，在网络带宽不发生大量拥塞的情况下，提高发送数据的带宽可以增加可靠性和实时性，在网络带宽大量拥塞时，提高数据发送量只会使得网络更加堵塞。增大丢包率和延迟。
TCP是累计确认，造成回ack包有一定的延迟，而lwip每个包收到后立即发送确认包。牺牲了带宽换来实时性，同时可以降低RTO
LWIP减小传输延迟的最关键部分就是如何准确判断数据包丢失并尽快重传。
检测RTT，减少RTO并每个包都立马回ack，nodelay
LWIP减少包头大小
不采取拥塞控制，自私点
13、TCP如何检测RTT？
14、TCP丢包即认为拥塞了
总结，降低延迟的关键在于 冗余+减少RTO+不做拥塞控制
网络要考虑三个维度
1）可靠性
2）实时性
3）带宽
IP分片会导致
。而一旦一个数据报文发生了IP分片，便会在数据链路层引入多次的传输和确认，加上报文的拆分和拼接开销，令得整个数据包的发送时延大大增加，并且，IP分片机制中，任何一个分片出现丢失时还会带来整个IP数据报文从最初的发起端重传的消耗。
TCP第三次握手包是否可以携带数据
可以的，但是要内核支持，linux貌似没看到有相应的接口，但是windows有提供 ConnectEx在连接第三个包的时候携带数据。一般是不携带的
TIME_WAIT
通信双方建立TCP连接后，主动关闭连接的一方就会进入TIME_WAIT状态。
客户端主动关闭连接时，会发送最后一个ack后，然后会进入TIME_WAIT状态，再停留2个MSL时间(后有MSL的解释)，进入CLOSED状态。
LASK_ACK状态
https://www.zhihu.com/question/27564314
b) 假如这个时候，A已经从TIME_WAIT状态变成了CLOSED状态
A收到这个FIN包后，认为这是一个错误的连接，向B发送一个RST包，当B收到这个RST包，进入CLOSED状态
c) 假如这个时候，A挂了（假如这台机器炸掉了）【第四种情况，不在参考链接里】
B没有收到A的回应，那么会继续发送FIN包，也就是触发了TCP的重传机制，如果A还是没有回应，B还会继续发送FIN包，直到重传超时(至于这个时间是多长需要仔细研究)，B重置这个连接，进入CLOSED状态，参考链接看这里
在tcp协议中处于last_ack状态的连接，如果一直收不到对方的ack，会一直处于这个状态吗？
全双工，不合在一起是因为对端可能还想发数据。
保持TIME_WAIT原因
可靠地实现TCP全双工连接的终止。给予足够时间允许对方重发fin包
允许老的重复分节在网络中消逝
tomcat与前端nginx之间的存在大量的TIME_WAIT状态的连接，第一反应是这里可能没有配置keep-alive。
https://elf8848.iteye.com/blog/1739571
MSL

MSL就是maximum segment lifetime(最大分节生命期），这是一个IP数据包能在互联网上生存的最长时间，超过这个时间IP数据包将在网络中消失 。MSL在RFC 1122上建议是2分钟，而源自berkeley的TCP实现传统上使用30秒。
为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？
MSL为报文最大生存时间
因为给对端回的FIN ack包有可能丢包，如果丢了会触发对端重传fin包，2MSL，一个MSL是ack到对端，另一个MSL是对端重发的FIN包
等待期该Socket Pair不能重用
首先主动关闭端会进入TIME_WAIT状态
TCP拥塞控制就是解决囚徒困境的
PKI
了解mmtls
如何防篡改，如何防重放
当第三次握手失败时的处理操作，可以看出当失败时服务器并不会重传ack报文，而是直接发送RTS报文段，进入CLOSED状态。这样做的目的是为了防止SYN洪泛攻击

帧同步
帧同步丢包，丢了就丢了，每个客户端都是以服务器组包结果为准，服务器给回来的包对了那就等待重传，udp冗余三桢

```java
public static void quick_sort(int arr[], int l, int r) {
    if(l >= r) {
        return;
    }
    int compareValue = arr[l];
    int i = l-1;
    int j = r+1;
    while(i < j) {
        do i++;while(arr[i]<p);
        do j++;while(arr[j]>p);
        if(i<j) {
            int temp = arr[i];
            arr[i] = arr[j];
            arr[j] = arr[i];
        }
    }
    quick_sort(arr,l,j);
    quick_sort(arr,j+1,r);
}
```

https://zhuanlan.zhihu.com/p/31805309





